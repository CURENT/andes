{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Parameter Sweeps and Batch Processing\n\nPower system studies frequently require running many simulations with systematically varied parameters. You might want to understand how load levels affect voltage stability, how different fault locations impact system response, or how controller tuning parameters influence dynamic behavior. Rather than manually running each scenario one at a time, ANDES provides several approaches for batch processing that can dramatically reduce the time required for comprehensive studies.\n\nThis tutorial covers three approaches to batch simulation: file-based parallel processing for large studies, in-memory loops for smaller studies, and the `pool` option for intermediate cases where you want both parallelism and programmatic access to results.\n\n:::{note}\n**Prerequisites:** This tutorial assumes familiarity with Python fundamentals including loops, dictionaries, and NumPy arrays. Complete {doc}`02-first-simulation` through {doc}`07-eigenvalue-analysis` before proceeding.\n:::"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import andes\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "andes.config_logger(stream_level=30)  # Reduce logging verbosity for batch runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File-Based Batch Processing\n",
    "\n",
    "For large parametric studies involving hundreds or thousands of scenarios, the most efficient approach is to generate separate case files and then run them in parallel using the ANDES command-line interface. This approach leverages multi-core processors effectively and allows you to checkpoint progress by checking which output files exist.\n",
    "\n",
    "### Generating Case Files\n",
    "\n",
    "The workflow begins by loading a base case, modifying parameters programmatically, and saving each variation to a new file. In this example, we create three cases with load levels varying from 100% to 120% of the base value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory for the case files\n",
    "os.makedirs('batch_cases', exist_ok=True)\n",
    "\n",
    "# Load base case\n",
    "kundur = andes.get_case('kundur/kundur_full.xlsx')\n",
    "ss = andes.load(kundur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the base load value\n",
    "p0_base = ss.PQ.get('p0', 'PQ_0')\n",
    "print(f\"Base load: {p0_base:.2f} MW\")\n",
    "\n",
    "# Create cases with load varying from 100% to 120% of base\n",
    "N_CASES = 3\n",
    "p0_values = np.linspace(p0_base, 1.2 * p0_base, N_CASES)\n",
    "\n",
    "for value in p0_values:\n",
    "    ss.PQ.alter('p0', 'PQ_0', value)\n",
    "    file_name = f'batch_cases/kundur_p_{value:.2f}.xlsx'\n",
    "    andes.io.dump(ss, 'xlsx', file_name, overwrite=True)\n",
    "    print(f\"Created: {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Cases in Parallel\n",
    "\n",
    "Once the case files are generated, you can run all of them in parallel using the `andes run` command with wildcards. ANDES automatically detects the number of CPU cores and distributes the workload across them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all cases with time-domain simulation\n",
    "!andes run batch_cases/*.xlsx -r tds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to limit CPU usage (for example, to leave resources for other tasks on a shared workstation), use the `--ncpu` flag to specify the maximum number of parallel processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit to 2 parallel processes\n",
    "!andes run batch_cases/*.xlsx -r tds --ncpu 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returning System Objects for Post-Processing\n",
    "\n",
    "When you want to analyze results programmatically after batch execution, use `pool=True` in the Python API. This runs cases in parallel and returns a list of System objects that you can then analyze or plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all cases and return System objects\n",
    "systems = andes.run('batch_cases/*.xlsx', routine='tds', pool=True, verbose=30)\n",
    "\n",
    "print(f\"Completed {len(systems)} simulations\")\n",
    "print(f\"Type of each result: {type(systems[0]).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results from all cases side by side\n",
    "fig, axes = plt.subplots(1, len(systems), figsize=(12, 4))\n",
    "\n",
    "for i, sys in enumerate(systems):\n",
    "    sys.TDS.plt.plot(sys.GENROU.omega, ax=axes[i], \n",
    "                     title=f'Case {i+1}', latex=False, show=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-Memory Parameter Sweeps\n",
    "\n",
    "For smaller studies where generating files would be unnecessary overhead, you can simply loop through parameter values in Python and accumulate results. This approach is particularly useful for quick exploratory analysis during model development or for sweeps involving only a few cases.\n",
    "\n",
    "### Power Flow Parameter Sweep\n",
    "\n",
    "The following example sweeps load levels and records the resulting bus voltage profiles. Since power flow converges quickly, this type of sweep can complete in seconds even for many parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load system\n",
    "ss = andes.run(kundur, no_output=True, default_config=True, verbose=30)\n",
    "\n",
    "# View current load parameters\n",
    "ss.PQ.as_df(vin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter sweep range\n",
    "n_samples = 5\n",
    "pq0_values = np.linspace(10, 14, n_samples)  # MW range for PQ_0\n",
    "\n",
    "# Storage for results: voltage at each bus for each parameter value\n",
    "v_results = np.zeros((ss.Bus.n, n_samples))\n",
    "\n",
    "# Run power flow for each load level\n",
    "for i, p0 in enumerate(pq0_values):\n",
    "    ss.PQ.alter('p0', 'PQ_0', p0)\n",
    "    ss.PFlow.run()\n",
    "    v_results[:, i] = ss.dae.y[ss.Bus.v.a]\n",
    "\n",
    "print(f\"Completed {n_samples} power flow calculations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how voltage profiles change with load level\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(n_samples):\n",
    "    plt.plot(v_results[:, i], 'o-', label=f'P0={pq0_values[i]:.1f} MW')\n",
    "\n",
    "plt.xlabel('Bus Index')\n",
    "plt.ylabel('Voltage [p.u.]')\n",
    "plt.title('Voltage Profile vs Load Level')\n",
    "plt.legend()\n",
    "plt.xticks(range(ss.Bus.n), ss.Bus.name.v, rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Time-Domain Simulation\n",
    "\n",
    "The same looping approach works for time-domain simulations, though each iteration takes longer. This example demonstrates running multiple contingency scenarios with different line trips. For each scenario, we create a fresh System object, add the appropriate disturbance, run the simulation, and store the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find available lines for contingency analysis\n",
    "ss = andes.load(kundur, setup=False)\n",
    "print(f\"Available lines: {ss.Line.idx.v}\")\n",
    "\n",
    "# Select a subset for demonstration\n",
    "lines_to_test = ss.Line.idx.v[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()\n",
    "\n",
    "for line_idx in lines_to_test:\n",
    "    # Load fresh system with setup=False to allow adding devices\n",
    "    ss = andes.load(kundur, setup=False)\n",
    "    \n",
    "    # Add line trip at t=1.0s, restore at t=1.1s\n",
    "    ss.add('Toggle', dict(model='Line', dev=line_idx, t=1.0))\n",
    "    ss.add('Toggle', dict(model='Line', dev=line_idx, t=1.1))\n",
    "    \n",
    "    # Finalize system setup\n",
    "    ss.setup()\n",
    "    \n",
    "    # Disable any existing Toggle from the test case\n",
    "    ss.Toggle.alter('u', 1, 0.0)\n",
    "    \n",
    "    # Run simulation\n",
    "    ss.PFlow.run()\n",
    "    ss.TDS.config.tf = 5\n",
    "    ss.TDS.config.no_tqdm = 1\n",
    "    ss.TDS.run()\n",
    "    \n",
    "    results[line_idx] = ss\n",
    "    print(f\"Completed: {line_idx} trip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare generator response across contingencies\n",
    "fig, axes = plt.subplots(1, len(results), figsize=(12, 4))\n",
    "\n",
    "for ax, (line_idx, ss) in zip(axes, results.items()):\n",
    "    ss.TDS.plt.plot(ss.GENROU.omega, ax=ax, \n",
    "                    title=f'{line_idx} Trip', latex=False, show=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the Right Approach\n",
    "\n",
    "The following table summarizes when to use each batch processing technique:\n",
    "\n",
    "| Approach | Best For | Parallelism | Memory Usage |\n",
    "|----------|----------|-------------|---------------|\n",
    "| File-based CLI | Large studies (>100 cases), production runs | Multi-process | Low (one case at a time) |\n",
    "| `pool=True` API | Medium studies, need results in memory | Multi-process | High (all results in memory) |\n",
    "| Python loop | Small studies, rapid prototyping | Single-thread | Controlled (can discard results) |\n",
    "\n",
    "For studies with more than about 10 cases, the file-based parallel approach is usually fastest because it fully utilizes all CPU cores. For smaller studies or when you are actively developing and testing, the simpler Python loop avoids the overhead of file I/O."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('batch_cases', ignore_errors=True)\n",
    "!andes misc -C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- {doc}`09-contingency-analysis` - Systematic N-1 contingency screening\n",
    "- {doc}`10-dynamic-control` - Runtime parameter modifications\n",
    "- {doc}`11-frequency-response` - Frequency response analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}